# SploitGPT Configuration (copy this file to .env and edit values)
# Compatible with Docker Compose and Podman Compose

# LLM / Ollama
# Default points at the containerized Ollama service on the private network.
SPLOITGPT_OLLAMA_HOST=http://ollama:11434
# Use the fine-tuned SploitGPT v5.10e model (Q5 quantization)
SPLOITGPT_MODEL=sploitgpt-7b-v5.10e:q5
SPLOITGPT_LLM_MODEL=sploitgpt-7b-v5.10e:q5
# Alternative for lower memory systems (Q4 quantization)
# SPLOITGPT_MODEL=sploitgpt-7b-v5.10e:q4
# SPLOITGPT_LLM_MODEL=sploitgpt-7b-v5.10e:q4

# Optional: if you run Ollama on the host instead of in a container:
# - For Docker: SPLOITGPT_OLLAMA_HOST=http://host.docker.internal:11434
# - For Podman: SPLOITGPT_OLLAMA_HOST=http://host.containers.internal:11434
# - Direct:     SPLOITGPT_OLLAMA_HOST=http://127.0.0.1:11434

# Path to host Ollama models directory (for containerized Ollama)
OLLAMA_MODELS_DIR=~/.ollama

# Metasploit RPC (runs inside container by default)
SPLOITGPT_MSF_HOST=127.0.0.1
SPLOITGPT_MSF_PORT=55553
SPLOITGPT_MSF_PASSWORD=sploitgpt
SPLOITGPT_MSF_SSL=false
SPLOITGPT_MSF_VERIFY_SSL=true

# Listener port guidance (ports open only when tools bind)
SPLOITGPT_LPORT=40000
SPLOITGPT_LISTENER_PORTS=40000-40100

# Optional: HuggingFace token (leave blank if unused)
SPLOITGPT_HF_TOKEN=

# Optional: Shodan (tooling) API key
SHODAN_API_KEY=
