model_list:
  - model_name: sploitgpt-local
    litellm_params:
      # Point LiteLLM at the local Ollama instance
      model: ollama/sploitgpt-local
      api_base: http://172.17.0.1:11434
      temperature: 0.7
      top_p: 0.9
      num_ctx: 8192

general_settings:
  # Keep the proxy lightweight; adjust if you want more concurrency
  timeout: 360
  max_new_tokens: 4096
